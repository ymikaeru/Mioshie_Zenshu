import json
import time
import os
import re
import google.generativeai as genai

# --- CONFIGURA√á√ÉO ---
API_KEY = "AIzaSyDQAbBRT4SxMwdDMAwD-EGker5wp55gKNw"
SOURCE_JSON = 'gosanka/yamato_full.json'
OUTPUT_FILE = 'Data/missing_deepening.md'

# --- CONFIGURA√á√ÉO DA IA ---
genai.configure(api_key=API_KEY)
# Using standard Pro model for quality.
model = genai.GenerativeModel('gemini-pro-latest') 

PROMPT_SISTEMA = """
Voc√™ √© um tradutor especialista em literatura japonesa e espiritualidade, focado na obra de Mokichi Okada (Meishu-Sama).
Sua tarefa √© traduzir poemas (Waka/Tanka) do japon√™s para o portugu√™s, seguindo o "Modelo de Profundidade M√°xima".

**Regras de Estilo e Conte√∫do:**
1.  **Tradu√ß√£o Art√≠stica:** N√£o fa√ßa tradu√ß√µes literais. Capte a "alma" do poema e reescreva em portugu√™s po√©tico, fluido e elevado.
2.  **An√°lise Trindade:** Para CADA poema, voc√™ deve fornecer:
    *   **Kigo (A Esta√ß√£o e o Clima):** Identifique a palavra de esta√ß√£o (Kigo) ou o sentimento sazonal/atmosf√©rico.
    *   **Kototama (A Sonoridade):** Analise os sons (rimas, alitera√ß√µes, ritmo) e o "esp√≠rito das palavras" japonesas relevantes.
    *   **A Profundidade (Li√ß√£o Espiritual):** O mais importante. Explique o ensinamento espiritual oculto (Filosofia de Mokichi Okada), conectando a natureza/arte √† Lei Divina, Makoto (Sinceridade), ou Salva√ß√£o.
3.  **Formata√ß√£o:** Siga estritamente o template abaixo. Use emojis exatos.

**Template de Sa√≠da para CADA Poema:**

## [N√∫mero]. [T√≠tulo Criativo em Portugu√™s]

**Original:** [Texto Japon√™s] **Leitura:** [Romaji]

**Tradu√ß√£o Art√≠stica:**

"[Texto da Tradu√ß√£o em Portugu√™s]"

**üçÉ Kigo (A Esta√ß√£o e o Clima):** [An√°lise]

**üéµ Kototama (A Sonoridade):** [An√°lise]

**üèîÔ∏è A Profundidade (Li√ß√£o Espiritual):** [An√°lise]

---
"""

def load_missing_poems(path):
    print(f"Lendo dados de: {path}")
    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    missing = []
    if 'sections' not in data:
        return missing

    for section in data['sections']:
        for poem in section['poems']:
            # Check if deepening is missing or empty
            if not poem.get('deepening') or not poem.get('deepening').strip():
                try:
                    # Enrich with section title for context if needed
                    poem_data = {
                        'id': poem['number'],
                        'original': poem['original'],
                        'reading': poem['reading'],
                        'section': section['title_pt']
                    }
                    missing.append(poem_data)
                except Exception as e:
                    print(f"Skipping malformed poem: {poem} - {e}")
    
    return missing

def translate_batch(batch, attempt=1):
    prompt_content = ""
    for p in batch:
        prompt_content += f"Poema {p['id']} (Se√ß√£o: {p['section']}):\nOriginal: {p['original']}\nLeitura: {p['reading']}\n\n"
    
    full_prompt = f"{PROMPT_SISTEMA}\n\n**POEMAS A TRADUZIR:**\n{prompt_content}"
    
    try:
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        error_str = str(e)
        if "429" in error_str or "Quota" in error_str or "Resource" in error_str:
            if attempt <= 5:
                wait_time = attempt * 10 # Exponential-ish: 10, 20, 30...
                print(f"  -> Quota excedida. Aguardando {wait_time}s antes de tentar novamente (Tentativa {attempt}/5)...")
                time.sleep(wait_time)
                return translate_batch(batch, attempt + 1)
            else:
                print(f"  -> FALHA FATAL: Max retries exceeded for batch.")
                return None
        else:
            print(f"Error generating content: {e}")
            return None

def get_existing_ids(filepath):
    if not os.path.exists(filepath):
        return set()
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    return set(int(x) for x in re.findall(r'##\s+(\d+)\.', content))

def main():
    print("--- INICIANDO TRADU√á√ÉO DE ITENS FALTANTES ---")
    
    poems_to_translate = load_missing_poems(SOURCE_JSON)
    existing_ids = get_existing_ids(OUTPUT_FILE)
    
    # Filter out existing
    poems_to_translate = [p for p in poems_to_translate if p['id'] not in existing_ids]
    
    print(f"Total faltando originalmente: {len(poems_to_translate) + len(existing_ids)}")
    print(f"J√° traduzidos: {len(existing_ids)}")
    print(f"Restantes para traduzir: {len(poems_to_translate)}")
    
    if not poems_to_translate:
        print("Todos os poemas j√° foram traduzidos!")
        return

    BATCH_SIZE = 5
    successful_translations = []

    for i in range(0, len(poems_to_translate), BATCH_SIZE):
        batch = poems_to_translate[i : i+BATCH_SIZE]
        ids = [p['id'] for p in batch]
        print(f"Traduzindo batch {i//BATCH_SIZE + 1}/{(len(poems_to_translate)-1)//BATCH_SIZE + 1} -> IDs: {ids}")
        
        result_text = translate_batch(batch)
        
        if result_text:
            successful_translations.append(result_text)
            # Append immediately to file to save progress
            with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:
                f.write(result_text + "\n")
            print("  -> Salvo no arquivo.")
        else:
            print("  -> FALHA no batch.")
            
        time.sleep(2) # Avoid rate limits

    print(f"\nConclu√≠do! Verifique o arquivo: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
